# robots.txt for portfolio website
# This file tells search engine crawlers which parts of the site should not be crawled

# Rules for all web crawlers
User-agent: *
# Allow crawling of all content
Allow: /
# Except the admin area
Disallow: /admin/

# Rules for specific bots
# Google
User-agent: Googlebot
Allow: /
Disallow: /admin/

# Bing
User-agent: Bingbot
Allow: /
Disallow: /admin/

# Suggested crawl delay (not supported by all bots)
Crawl-delay: 10
